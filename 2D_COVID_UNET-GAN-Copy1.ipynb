{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "9RYTSpRCxcwM"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import nibabel as nib\n",
    "from scipy import ndimage\n",
    "from sklearn import preprocessing\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Add, Rescaling , Multiply, SeparableConv2D, Conv2D, Conv1D, Subtract, Conv2DTranspose, UpSampling2D, Dropout, BatchNormalization, Dense, Activation, concatenate, PReLU , UpSampling2D, GlobalAveragePooling2D, AveragePooling2D, Lambda, Concatenate, LeakyReLU, Reshape, Permute,PReLU, Flatten, MaxPooling2D\n",
    "import tensorflow.keras.backend as K\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "from keras_unet_collection import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EfA0KgiIZ2fu",
    "outputId": "f21b95dc-522e-4552-c908-9f4e8832f90c"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import mixed_precision\n",
    "# policy = mixed_precision.Policy('mixed_float16')\n",
    "# mixed_precision.set_global_policy(policy)\n",
    "# print('Compute dtype: %s' % policy.compute_dtype)\n",
    "# print('Variable dtype: %s' % policy.variable_dtype)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vSCTWS0lxcwb",
    "outputId": "b69de6fd-dc0b-4e3a-f31e-a3b7afbda063"
   },
   "outputs": [],
   "source": [
    "Train_Image = \"SEGMENTATION DATASET IMAGES/Train/Images/\"\n",
    "Train_Mask = \"SEGMENTATION DATASET IMAGES/Train/Masks/\"\n",
    "Valid_Image = \"SEGMENTATION DATASET IMAGES/Valid/Images/\"\n",
    "Valid_Mask = \"SEGMENTATION DATASET IMAGES/Valid/Masks/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "EsWaA7Ovxcwb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2026 images belonging to 1 classes.\n",
      "Found 2026 images belonging to 1 classes.\n",
      "Found 767 images belonging to 1 classes.\n",
      "Found 767 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "def preprocess(image):\n",
    "  return image/255.\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# train_datagen = ImageDataGenerator(rotation_range=60,\n",
    "#                                    horizontal_flip = True, vertical_flip = True\n",
    "#                                    , preprocessing_function=preprocess)\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess)\n",
    "seed = 1000\n",
    "batch_size = 32\n",
    "train_image_generator = train_datagen.flow_from_directory(Train_Image, seed=seed, batch_size= batch_size, shuffle = True,  class_mode = None)\n",
    "\n",
    "train_mask_generator = train_datagen.flow_from_directory(Train_Mask, seed=seed, batch_size = batch_size, shuffle = True, color_mode = \"grayscale\", class_mode = None)\n",
    "\n",
    "train_generator = zip(train_image_generator, train_mask_generator)\n",
    "\n",
    "valid_datagen = ImageDataGenerator(preprocessing_function=preprocess)\n",
    "\n",
    "val_image_generator = valid_datagen.flow_from_directory(Valid_Image, batch_size= 767, shuffle = False)\n",
    "\n",
    "val_mask_generator = valid_datagen.flow_from_directory(Valid_Mask, batch_size = 767, shuffle = False, color_mode = \"grayscale\")\n",
    "\n",
    "val_generator = zip(val_image_generator, val_mask_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Valid_Images,Valid_Masks = next(val_generator)\n",
    "Valid_Images = Valid_Images[0]\n",
    "Valid_Masks = Valid_Masks[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "AEeAzg1Excwf"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def jaccard_score(y_true, y_pred, smooth=1e-6):\n",
    "    \"\"\"Jaccard distance for semantic segmentation.\n",
    "    Also known as the intersection-over-union loss.\n",
    "    This loss is useful when you have unbalanced numbers of pixels within an image\n",
    "    because it gives all classes equal weight. However, it is not the defacto\n",
    "    standard for image segmentation.\n",
    "    For example, assume you are trying to predict if\n",
    "    each pixel is cat, dog, or background.\n",
    "    You have 80% background pixels, 10% dog, and 10% cat.\n",
    "    If the model predicts 100% background\n",
    "    should it be be 80% right (as with categorical cross entropy)\n",
    "    or 30% (with this loss)?\n",
    "    The loss has been modified to have a smooth gradient as it converges on zero.\n",
    "    This has been shifted so it converges on 0 and is smoothed to avoid exploding\n",
    "    or disappearing gradient.\n",
    "    Jaccard = (|X & Y|)/ (|X|+ |Y| - |X & Y|)\n",
    "            = sum(|A*B|)/(sum(|A|)+sum(|B|)-sum(|A*B|))\n",
    "    # Arguments\n",
    "        y_true: The ground truth tensor.\n",
    "        y_pred: The predicted tensor\n",
    "        smooth: Smoothing factor. Default is 100.\n",
    "    # Returns\n",
    "        The Jaccard distance between the two tensors.\n",
    "    # References\n",
    "        - [What is a good evaluation measure for semantic segmentation?](\n",
    "           http://www.bmva.org/bmvc/2013/Papers/paper0032/paper0032.pdf)\n",
    "    \"\"\"\n",
    "    axis = -1\n",
    "    y_pred = K.flatten(y_pred)\n",
    "    y_true = K.flatten(y_true)\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=axis)\n",
    "    sum_ = K.sum(K.abs(y_true) + K.abs(y_pred), axis=axis)\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "    return jac\n",
    "\n",
    "\n",
    "def jaccard_distance (y_true, y_pred, smooth=1):\n",
    "    return 1 - jaccard_score(y_true, y_pred, smooth=1e-6) * smooth\n",
    "\n",
    "\n",
    "def dice_coef(y_true, y_pred, epsilon=0.00001):\n",
    "    \"\"\"\n",
    "    Dice = (2*|X & Y|)/ (|X|+ |Y|)\n",
    "         =  2*sum(|A*B|)/(sum(A^2)+sum(B^2))\n",
    "    ref: https://arxiv.org/pdf/1606.04797v1.pdf\n",
    "    \n",
    "    \"\"\"\n",
    "    axis = -1\n",
    "    y_pred = K.flatten(y_pred)\n",
    "    y_true = K.flatten(y_true)\n",
    "    dice_numerator = 2. * K.sum(y_true * y_pred, axis=axis) + epsilon\n",
    "    dice_denominator = K.sum(y_true*y_true, axis=axis) + K.sum(y_pred*y_pred, axis=axis) + epsilon\n",
    "    return K.mean((dice_numerator)/(dice_denominator))\n",
    "\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1-dice_coef(y_true, y_pred)\n",
    "\n",
    "\n",
    "\n",
    "ALPHA = 0.5\n",
    "BETA = 0.5\n",
    "GAMMA = 3/4\n",
    "\n",
    "def FocalTverskyLoss(y_true, y_pred, alpha=ALPHA, beta=BETA, gamma=GAMMA, smooth=1e-6):\n",
    "    \n",
    "        #flatten label and prediction tensors\n",
    "        y_pred = K.flatten(y_pred)\n",
    "        y_true = K.flatten(y_true)\n",
    "        axis = -1\n",
    "        #True Positives, False Positives & False Negatives\n",
    "        TP = K.sum(y_true * y_pred, axis=axis)\n",
    "        FP = K.sum(y_true * (1-y_pred), axis=axis)\n",
    "        FN = K.sum((1-y_true) * y_pred, axis=axis)\n",
    "               \n",
    "        Tversky = (TP + smooth) / (TP + alpha*FP + beta*FN + smooth)  \n",
    "        FocalTversky = K.pow((1 - Tversky), gamma)\n",
    "        \n",
    "        return FocalTversky\n",
    "\n",
    "\n",
    "def Tversky (y_true, y_pred, smooth=1e-6):\n",
    "            #flatten label and prediction tensors\n",
    "        alpha = .3\n",
    "        beta = 1 - alpha \n",
    "        y_pred = K.flatten(y_pred)\n",
    "        y_true = K.flatten(y_true)\n",
    "        \n",
    "        #True Positives, False Positives & False Negatives\n",
    "        TP = K.sum((y_pred * y_true))\n",
    "        FP = K.sum(((1-y_true) * y_pred))\n",
    "        FN = K.sum((y_true * (1-y_pred)))\n",
    "               \n",
    "        Tversky = (TP + smooth) / (TP + alpha*FP + beta*FN + smooth)  \n",
    "        return Tversky\n",
    "    \n",
    "def Tversky_loss (y_true, y_pred, smooth=1e-6):\n",
    "    return 1 - Tversky (y_true, y_pred, smooth)\n",
    "\n",
    "def Tversky_crossentropy(y_true, y_pred):\n",
    "    Tversky = K.pow(Tversky_loss(y_true, y_pred),3/4)\n",
    "    crossentropy = K.binary_crossentropy(y_true, y_pred)\n",
    "    crossentropy = K.mean(crossentropy)\n",
    "    \n",
    "    return Tversky + crossentropy\n",
    "def DiceBCELoss(y_true, y_pred, smooth=1e-6):    \n",
    "       \n",
    "    #flatten label and prediction tensors\n",
    "    #y_pred = K.flatten(y_pred)\n",
    "    #y_true = K.flatten(y_true)\n",
    "    \n",
    "    BCE =  K.binary_crossentropy(y_true, y_pred)\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=(0,1,2,3))  \n",
    "    dice_loss = 1 - (2*intersection + smooth) / (K.sum(y_true) + K.sum(y_pred) + smooth)\n",
    "    Dice_BCE = BCE + dice_loss\n",
    "    \n",
    "    return Dice_BCE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def euclidean_distance_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Euclidean distance loss\n",
    "    https://en.wikipedia.org/wiki/Euclidean_distance\n",
    "    :param y_true: TensorFlow tensor\n",
    "    :param y_pred: TensorFlow tensor of the same shape as y_true\n",
    "    :return: float\n",
    "    \"\"\"\n",
    "    return K.sqrt(K.sum(K.square(y_pred - y_true), axis=-1))\n",
    "\n",
    "\n",
    "def binary_recall_specificity(y_true, y_pred, recall_weight, spec_weight):\n",
    "    y_pred = K.flatten(y_pred)\n",
    "    y_true = K.flatten(y_true)\n",
    "    \n",
    "    TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    TN = K.sum(K.round(K.clip((1 - y_true) * (1 - y_pred), 0, 1)))\n",
    "    FP = K.sum(K.round(K.clip((1 - y_true) * y_pred, 0, 1)))\n",
    "    FN = K.sum(K.round(K.clip(y_true * (1 - y_pred), 0, 1)))\n",
    "\n",
    "    # Converted as Keras Tensors\n",
    "\n",
    "\n",
    "    specificity = TN / (TN + FP + K.epsilon())\n",
    "    recall = TP / (TP + FN + K.epsilon())\n",
    "\n",
    "    return 1.0 - (recall_weight*recall + spec_weight*specificity)\n",
    "\n",
    "def custom_loss(recall_weight, spec_weight):\n",
    "\n",
    "    def recall_spec_loss(y_true, y_pred):\n",
    "        return binary_recall_specificity(y_true, y_pred, recall_weight, spec_weight)\n",
    "\n",
    "    # Returns the (y_true, y_pred) loss function\n",
    "    return recall_spec_loss\n",
    "\n",
    "\n",
    "def mix_loss(y_true, y_pred):\n",
    "    FTC = FocalTverskyLoss(y_true, y_pred)\n",
    "    DCB = DiceBCELoss(y_true, y_pred)\n",
    "    return FTC + DCB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "M9n2fevbxcwg"
   },
   "outputs": [],
   "source": [
    "# weight: weighted tensor(same shape with mask image)\n",
    "def weighted_bce_loss(y_true, y_pred, weight):\n",
    "    # avoiding overflow\n",
    "    epsilon = 1e-7\n",
    "    y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "    logit_y_pred = K.log(y_pred / (1. - y_pred))\n",
    "    \n",
    "    # https://www.tensorflow.org/api_docs/python/tf/nn/weighted_cross_entropy_with_logits\n",
    "    loss = (1. - y_true) * logit_y_pred + (1. + (weight - 1.) * y_true) * \\\n",
    "    (K.log(1. + K.exp(-K.abs(logit_y_pred))) + K.maximum(-logit_y_pred, 0.))\n",
    "    return K.sum(loss) / K.sum(weight)\n",
    "\n",
    "def weighted_dice_loss(y_true, y_pred, weight):\n",
    "    smooth = 1e-6\n",
    "    w, m1, m2 = weight * weight, y_true, y_pred\n",
    "    intersection = (m1 * m2)\n",
    "    score = (2. * K.sum(w * intersection) + smooth) / (K.sum(w * m1) + K.sum(w * m2) + smooth)\n",
    "    loss = 1. - K.sum(score)\n",
    "    return loss\n",
    "\n",
    "def weighted_bce_dice_loss(y_true, y_pred):\n",
    "    y_true = K.cast(y_true, 'float32')\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    # if we want to get same size of output, kernel size must be odd number\n",
    "    averaged_mask = K.pool2d(\n",
    "            y_true, pool_size=(11, 11), strides=(1, 1), padding='same', pool_mode='avg')\n",
    "    border = K.cast(K.greater(averaged_mask, 0.005), 'float32') * K.cast(K.less(averaged_mask, 0.995), 'float32')\n",
    "    weight = K.ones_like(averaged_mask)\n",
    "    w0 = K.sum(weight)\n",
    "    weight += border * 2\n",
    "    w1 = K.sum(weight)\n",
    "    weight *= (w0 / w1)\n",
    "    loss = weighted_bce_loss(y_true, y_pred, weight) + \\\n",
    "    weighted_dice_loss(y_true, y_pred, weight)\n",
    "    return loss\n",
    "\n",
    "\n",
    "\n",
    "def SSIM (y_true, y_pred):\n",
    "    return tf.image.ssim(y_true, y_pred, max_val = 1.0) \n",
    "\n",
    "def SSIM_LOSS (y_true, y_pred):\n",
    "    return (1 - SSIM(y_true,y_pred))\n",
    "\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    y_pred = K.flatten(y_pred)\n",
    "    y_true = K.flatten(y_true)\n",
    "    \n",
    "    TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    TN = K.sum(K.round(K.clip((1 - y_true) * (1 - y_pred), 0, 1)))\n",
    "    FP = K.sum(K.round(K.clip((1 - y_true) * y_pred, 0, 1)))\n",
    "    FN = K.sum(K.round(K.clip(y_true * (1 - y_pred), 0, 1)))\n",
    "\n",
    "    # Converted as Keras Tensors\n",
    "\n",
    "\n",
    "    return (TP/(TP+(0.5 * (FP+FN))))\n",
    "\n",
    "from scipy.ndimage import distance_transform_edt as distance\n",
    "\n",
    "\n",
    "def calc_dist_map(seg):\n",
    "    res = np.zeros_like(seg)\n",
    "    posmask = seg.astype(np.bool)\n",
    "\n",
    "    if posmask.any():\n",
    "        negmask = ~posmask\n",
    "        res = distance(negmask) * negmask - (distance(posmask) - 1) * posmask\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "def calc_dist_map_batch(y_true):\n",
    "    y_true_numpy = y_true.numpy()\n",
    "    return np.array([calc_dist_map(y)\n",
    "                     for y in y_true_numpy]).reshape(y_true.shape).astype(np.float32)\n",
    "\n",
    "\n",
    "def surface_loss_keras(y_true, y_pred):\n",
    "    y_true_dist_map = tf.py_function(func=calc_dist_map_batch,\n",
    "                                     inp=[y_true],\n",
    "                                     Tout=tf.float32)\n",
    "    multipled = y_pred * y_true_dist_map\n",
    "    return K.mean(multipled)\n",
    "\n",
    "def Combo_loss(targets, inputs, eps=1e-9):\n",
    "        ALPHA = 0.5# < 0.5 penalises FP more, > 0.5 penalises FN         more\n",
    "        CE_RATIO = 0.5 #weighted contribution of modified CE loss compared to Dice loss\n",
    "        smooth = 1\n",
    "        targets = K.flatten(targets)\n",
    "        inputs = K.flatten(inputs)\n",
    "                \n",
    "        intersection = K.sum(targets * inputs)\n",
    "        dice = (2. * intersection + smooth) / (K.sum(targets) + K.sum(inputs) + smooth)\n",
    "        inputs = K.clip(inputs, eps, 1.0 - eps)\n",
    "        out = - (ALPHA * ((targets * K.log(inputs)) + ((1 - ALPHA) * (1.0 - targets) * K.log(1.0 - inputs))))\n",
    "        weighted_ce = K.mean(out, axis=-1)\n",
    "        combo = (CE_RATIO * weighted_ce) - ((1 - CE_RATIO) * dice)\n",
    "                          \n",
    "def wasserstein_loss(y_true, y_pred):\n",
    "    y_true = K.flatten(y_true)\n",
    "    y_pred = K.flatten(y_pred)\n",
    "    return K.mean(y_true * y_pred) \n",
    "\n",
    "\n",
    "\n",
    "def log_cosh_dice(y_true, y_pred):\n",
    "    x = dice_coef_loss(y_true, y_pred)\n",
    "    cosh_x = (K.exp(x) + K.exp(-x))/2\n",
    "    loss = K.log(cosh_x)\n",
    "    return loss\n",
    "\n",
    "def mix_loss(y_true, y_pred):\n",
    "    FTC = Tversky_crossentropy(y_true, y_pred)\n",
    "    SSIM = SSIM_LOSS(y_true, y_pred)\n",
    "    SL = surface_loss_keras(y_true, y_pred)\n",
    "    return  FTC + SL * .1 + SSIM * 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GAN():\n",
    "    \n",
    "    def __init__(self, input_height, input_width, c_dim):\n",
    "        self.input_height = input_height\n",
    "        self.input_width = input_width\n",
    "        self.c_dim = c_dim\n",
    "\n",
    "    def build_segmentor(self):\n",
    "        \n",
    "        model = models.unet_2d((None, None, 3), filter_num=[64, 128, 256, 512, 1024], n_labels=1, \n",
    "                           stack_num_down=2, stack_num_up=2, activation='ReLU', \n",
    "                           output_activation='Sigmoid', \n",
    "                           batch_norm=True, pool=False, unpool=False, \n",
    "                           backbone='VGG16', weights='imagenet', \n",
    "                           freeze_backbone=True, freeze_batch_norm=True, \n",
    "                           name='unet')\n",
    "        return model\n",
    "\n",
    "    def build_discriminator(self):\n",
    "        in_img = Input(shape = (None,None,1) ) \n",
    "\n",
    "        C1 = Conv2D(filters = 64, kernel_size = 3, strides = 2, padding=\"same\") (in_img)\n",
    "        C1 = BatchNormalization() (C1)\n",
    "        C1 = PReLU(shared_axes=[1,2]) (C1)\n",
    "        \n",
    "        C2 = Conv2D(filters = 128, kernel_size = 3, strides = 2, padding=\"same\") (C1)\n",
    "        C2 = BatchNormalization() (C2)\n",
    "        C2 = PReLU(shared_axes=[1,2]) (C2)\n",
    "        \n",
    "        C3 = Conv2D(filters = 256, kernel_size = 3, strides = 2, padding=\"same\") (C2)\n",
    "        C3 = BatchNormalization() (C3)\n",
    "        C3 = PReLU(shared_axes=[1,2]) (C3)\n",
    "        \n",
    "        C4 = Conv2D(filters = 512, kernel_size = 3, strides = 2, padding=\"same\") (C3)\n",
    "        C4 = BatchNormalization() (C4)\n",
    "        C4 = PReLU(shared_axes=[1,2]) (C4)\n",
    "        \n",
    "        C5 = Conv2D(filters = 1024, kernel_size = 3, strides = 1, padding=\"same\") (C4)\n",
    "        C5 = BatchNormalization() (C5)\n",
    "        C5 = PReLU(shared_axes=[1,2]) (C5)\n",
    "        \n",
    "        model = GlobalAveragePooling2D()(C5)\n",
    "        model = Dense(256)(model)\n",
    "        model = PReLU(shared_axes=[1])(model)\n",
    "        model = Dense(512)(model)\n",
    "        model = PReLU(shared_axes=[1])(model)\n",
    "        output = Dense(1)(model)\n",
    "        output = Activation(\"sigmoid\") (output)\n",
    "        model = Model(inputs = in_img, outputs = output)\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\boude\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\keras_unet_collection\\_backbone_zoo.py:45: UserWarning: \n",
      "\n",
      "Backbone VGG16 does not use batch norm, but other layers received batch_norm=True\n",
      "  warnings.warn(param_mismatch);\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"unet_model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, None, None,  0           []                               \n",
      "                                 3)]                                                              \n",
      "                                                                                                  \n",
      " VGG16_backbone (Functional)    [(None, None, None,  14714688    ['input_1[0][0]']                \n",
      "                                 64),                                                             \n",
      "                                 (None, None, None,                                               \n",
      "                                 128),                                                            \n",
      "                                 (None, None, None,                                               \n",
      "                                 256),                                                            \n",
      "                                 (None, None, None,                                               \n",
      "                                 512),                                                            \n",
      "                                 (None, None, None,                                               \n",
      "                                 512)]                                                            \n",
      "                                                                                                  \n",
      " unet_up0_decode_trans_conv (Co  (None, None, None,   2359808    ['VGG16_backbone[0][4]']         \n",
      " nv2DTranspose)                 512)                                                              \n",
      "                                                                                                  \n",
      " unet_up0_decode_bn (BatchNorma  (None, None, None,   2048       ['unet_up0_decode_trans_conv[0][0\n",
      " lization)                      512)                             ]']                              \n",
      "                                                                                                  \n",
      " unet_up0_decode_activation (Re  (None, None, None,   0          ['unet_up0_decode_bn[0][0]']     \n",
      " LU)                            512)                                                              \n",
      "                                                                                                  \n",
      " unet_up0_conv_before_concat_0   (None, None, None,   2359296    ['unet_up0_decode_activation[0][0\n",
      " (Conv2D)                       512)                             ]']                              \n",
      "                                                                                                  \n",
      " unet_up0_conv_before_concat_0_  (None, None, None,   2048       ['unet_up0_conv_before_concat_0[0\n",
      " bn (BatchNormalization)        512)                             ][0]']                           \n",
      "                                                                                                  \n",
      " unet_up0_conv_before_concat_0_  (None, None, None,   0          ['unet_up0_conv_before_concat_0_b\n",
      " activation (ReLU)              512)                             n[0][0]']                        \n",
      "                                                                                                  \n",
      " unet_up0_concat (Concatenate)  (None, None, None,   0           ['unet_up0_conv_before_concat_0_a\n",
      "                                1024)                            ctivation[0][0]',                \n",
      "                                                                  'VGG16_backbone[0][3]']         \n",
      "                                                                                                  \n",
      " unet_up0_conv_after_concat_0 (  (None, None, None,   4718592    ['unet_up0_concat[0][0]']        \n",
      " Conv2D)                        512)                                                              \n",
      "                                                                                                  \n",
      " unet_up0_conv_after_concat_0_b  (None, None, None,   2048       ['unet_up0_conv_after_concat_0[0]\n",
      " n (BatchNormalization)         512)                             [0]']                            \n",
      "                                                                                                  \n",
      " unet_up0_conv_after_concat_0_a  (None, None, None,   0          ['unet_up0_conv_after_concat_0_bn\n",
      " ctivation (ReLU)               512)                             [0][0]']                         \n",
      "                                                                                                  \n",
      " unet_up0_conv_after_concat_1 (  (None, None, None,   2359296    ['unet_up0_conv_after_concat_0_ac\n",
      " Conv2D)                        512)                             tivation[0][0]']                 \n",
      "                                                                                                  \n",
      " unet_up0_conv_after_concat_1_b  (None, None, None,   2048       ['unet_up0_conv_after_concat_1[0]\n",
      " n (BatchNormalization)         512)                             [0]']                            \n",
      "                                                                                                  \n",
      " unet_up0_conv_after_concat_1_a  (None, None, None,   0          ['unet_up0_conv_after_concat_1_bn\n",
      " ctivation (ReLU)               512)                             [0][0]']                         \n",
      "                                                                                                  \n",
      " unet_up1_decode_trans_conv (Co  (None, None, None,   1179904    ['unet_up0_conv_after_concat_1_ac\n",
      " nv2DTranspose)                 256)                             tivation[0][0]']                 \n",
      "                                                                                                  \n",
      " unet_up1_decode_bn (BatchNorma  (None, None, None,   1024       ['unet_up1_decode_trans_conv[0][0\n",
      " lization)                      256)                             ]']                              \n",
      "                                                                                                  \n",
      " unet_up1_decode_activation (Re  (None, None, None,   0          ['unet_up1_decode_bn[0][0]']     \n",
      " LU)                            256)                                                              \n",
      "                                                                                                  \n",
      " unet_up1_conv_before_concat_0   (None, None, None,   589824     ['unet_up1_decode_activation[0][0\n",
      " (Conv2D)                       256)                             ]']                              \n",
      "                                                                                                  \n",
      " unet_up1_conv_before_concat_0_  (None, None, None,   1024       ['unet_up1_conv_before_concat_0[0\n",
      " bn (BatchNormalization)        256)                             ][0]']                           \n",
      "                                                                                                  \n",
      " unet_up1_conv_before_concat_0_  (None, None, None,   0          ['unet_up1_conv_before_concat_0_b\n",
      " activation (ReLU)              256)                             n[0][0]']                        \n",
      "                                                                                                  \n",
      " unet_up1_concat (Concatenate)  (None, None, None,   0           ['unet_up1_conv_before_concat_0_a\n",
      "                                512)                             ctivation[0][0]',                \n",
      "                                                                  'VGG16_backbone[0][2]']         \n",
      "                                                                                                  \n",
      " unet_up1_conv_after_concat_0 (  (None, None, None,   1179648    ['unet_up1_concat[0][0]']        \n",
      " Conv2D)                        256)                                                              \n",
      "                                                                                                  \n",
      " unet_up1_conv_after_concat_0_b  (None, None, None,   1024       ['unet_up1_conv_after_concat_0[0]\n",
      " n (BatchNormalization)         256)                             [0]']                            \n",
      "                                                                                                  \n",
      " unet_up1_conv_after_concat_0_a  (None, None, None,   0          ['unet_up1_conv_after_concat_0_bn\n",
      " ctivation (ReLU)               256)                             [0][0]']                         \n",
      "                                                                                                  \n",
      " unet_up1_conv_after_concat_1 (  (None, None, None,   589824     ['unet_up1_conv_after_concat_0_ac\n",
      " Conv2D)                        256)                             tivation[0][0]']                 \n",
      "                                                                                                  \n",
      " unet_up1_conv_after_concat_1_b  (None, None, None,   1024       ['unet_up1_conv_after_concat_1[0]\n",
      " n (BatchNormalization)         256)                             [0]']                            \n",
      "                                                                                                  \n",
      " unet_up1_conv_after_concat_1_a  (None, None, None,   0          ['unet_up1_conv_after_concat_1_bn\n",
      " ctivation (ReLU)               256)                             [0][0]']                         \n",
      "                                                                                                  \n",
      " unet_up2_decode_trans_conv (Co  (None, None, None,   295040     ['unet_up1_conv_after_concat_1_ac\n",
      " nv2DTranspose)                 128)                             tivation[0][0]']                 \n",
      "                                                                                                  \n",
      " unet_up2_decode_bn (BatchNorma  (None, None, None,   512        ['unet_up2_decode_trans_conv[0][0\n",
      " lization)                      128)                             ]']                              \n",
      "                                                                                                  \n",
      " unet_up2_decode_activation (Re  (None, None, None,   0          ['unet_up2_decode_bn[0][0]']     \n",
      " LU)                            128)                                                              \n",
      "                                                                                                  \n",
      " unet_up2_conv_before_concat_0   (None, None, None,   147456     ['unet_up2_decode_activation[0][0\n",
      " (Conv2D)                       128)                             ]']                              \n",
      "                                                                                                  \n",
      " unet_up2_conv_before_concat_0_  (None, None, None,   512        ['unet_up2_conv_before_concat_0[0\n",
      " bn (BatchNormalization)        128)                             ][0]']                           \n",
      "                                                                                                  \n",
      " unet_up2_conv_before_concat_0_  (None, None, None,   0          ['unet_up2_conv_before_concat_0_b\n",
      " activation (ReLU)              128)                             n[0][0]']                        \n",
      "                                                                                                  \n",
      " unet_up2_concat (Concatenate)  (None, None, None,   0           ['unet_up2_conv_before_concat_0_a\n",
      "                                256)                             ctivation[0][0]',                \n",
      "                                                                  'VGG16_backbone[0][1]']         \n",
      "                                                                                                  \n",
      " unet_up2_conv_after_concat_0 (  (None, None, None,   294912     ['unet_up2_concat[0][0]']        \n",
      " Conv2D)                        128)                                                              \n",
      "                                                                                                  \n",
      " unet_up2_conv_after_concat_0_b  (None, None, None,   512        ['unet_up2_conv_after_concat_0[0]\n",
      " n (BatchNormalization)         128)                             [0]']                            \n",
      "                                                                                                  \n",
      " unet_up2_conv_after_concat_0_a  (None, None, None,   0          ['unet_up2_conv_after_concat_0_bn\n",
      " ctivation (ReLU)               128)                             [0][0]']                         \n",
      "                                                                                                  \n",
      " unet_up2_conv_after_concat_1 (  (None, None, None,   147456     ['unet_up2_conv_after_concat_0_ac\n",
      " Conv2D)                        128)                             tivation[0][0]']                 \n",
      "                                                                                                  \n",
      " unet_up2_conv_after_concat_1_b  (None, None, None,   512        ['unet_up2_conv_after_concat_1[0]\n",
      " n (BatchNormalization)         128)                             [0]']                            \n",
      "                                                                                                  \n",
      " unet_up2_conv_after_concat_1_a  (None, None, None,   0          ['unet_up2_conv_after_concat_1_bn\n",
      " ctivation (ReLU)               128)                             [0][0]']                         \n",
      "                                                                                                  \n",
      " unet_up3_decode_trans_conv (Co  (None, None, None,   73792      ['unet_up2_conv_after_concat_1_ac\n",
      " nv2DTranspose)                 64)                              tivation[0][0]']                 \n",
      "                                                                                                  \n",
      " unet_up3_decode_bn (BatchNorma  (None, None, None,   256        ['unet_up3_decode_trans_conv[0][0\n",
      " lization)                      64)                              ]']                              \n",
      "                                                                                                  \n",
      " unet_up3_decode_activation (Re  (None, None, None,   0          ['unet_up3_decode_bn[0][0]']     \n",
      " LU)                            64)                                                               \n",
      "                                                                                                  \n",
      " unet_up3_conv_before_concat_0   (None, None, None,   36864      ['unet_up3_decode_activation[0][0\n",
      " (Conv2D)                       64)                              ]']                              \n",
      "                                                                                                  \n",
      " unet_up3_conv_before_concat_0_  (None, None, None,   256        ['unet_up3_conv_before_concat_0[0\n",
      " bn (BatchNormalization)        64)                              ][0]']                           \n",
      "                                                                                                  \n",
      " unet_up3_conv_before_concat_0_  (None, None, None,   0          ['unet_up3_conv_before_concat_0_b\n",
      " activation (ReLU)              64)                              n[0][0]']                        \n",
      "                                                                                                  \n",
      " unet_up3_concat (Concatenate)  (None, None, None,   0           ['unet_up3_conv_before_concat_0_a\n",
      "                                128)                             ctivation[0][0]',                \n",
      "                                                                  'VGG16_backbone[0][0]']         \n",
      "                                                                                                  \n",
      " unet_up3_conv_after_concat_0 (  (None, None, None,   73728      ['unet_up3_concat[0][0]']        \n",
      " Conv2D)                        64)                                                               \n",
      "                                                                                                  \n",
      " unet_up3_conv_after_concat_0_b  (None, None, None,   256        ['unet_up3_conv_after_concat_0[0]\n",
      " n (BatchNormalization)         64)                              [0]']                            \n",
      "                                                                                                  \n",
      " unet_up3_conv_after_concat_0_a  (None, None, None,   0          ['unet_up3_conv_after_concat_0_bn\n",
      " ctivation (ReLU)               64)                              [0][0]']                         \n",
      "                                                                                                  \n",
      " unet_up3_conv_after_concat_1 (  (None, None, None,   36864      ['unet_up3_conv_after_concat_0_ac\n",
      " Conv2D)                        64)                              tivation[0][0]']                 \n",
      "                                                                                                  \n",
      " unet_up3_conv_after_concat_1_b  (None, None, None,   256        ['unet_up3_conv_after_concat_1[0]\n",
      " n (BatchNormalization)         64)                              [0]']                            \n",
      "                                                                                                  \n",
      " unet_up3_conv_after_concat_1_a  (None, None, None,   0          ['unet_up3_conv_after_concat_1_bn\n",
      " ctivation (ReLU)               64)                              [0][0]']                         \n",
      "                                                                                                  \n",
      " unet_output (Conv2D)           (None, None, None,   65          ['unet_up3_conv_after_concat_1_ac\n",
      "                                1)                               tivation[0][0]']                 \n",
      "                                                                                                  \n",
      " unet_output_activation (Activa  (None, None, None,   0          ['unet_output[0][0]']            \n",
      " tion)                          1)                                                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 31,172,417\n",
      "Trainable params: 16,450,049\n",
      "Non-trainable params: 14,722,368\n",
      "__________________________________________________________________________________________________\n",
      "---------------------------------------------------------------\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, None, None, 1)]   0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, None, None, 64)    640       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, None, None, 64)   256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " p_re_lu (PReLU)             (None, None, None, 64)    64        \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, None, None, 128)   73856     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, None, None, 128)  512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " p_re_lu_1 (PReLU)           (None, None, None, 128)   128       \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, None, None, 256)   295168    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, None, None, 256)  1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " p_re_lu_2 (PReLU)           (None, None, None, 256)   256       \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, None, None, 512)   1180160   \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, None, None, 512)  2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " p_re_lu_3 (PReLU)           (None, None, None, 512)   512       \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, None, None, 1024)  4719616   \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, None, None, 1024)  4096     \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " p_re_lu_4 (PReLU)           (None, None, None, 1024)  1024      \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1024)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               262400    \n",
      "                                                                 \n",
      " p_re_lu_5 (PReLU)           (None, 256)               1         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               131584    \n",
      "                                                                 \n",
      " p_re_lu_6 (PReLU)           (None, 512)               1         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,673,859\n",
      "Trainable params: 0\n",
      "Non-trainable params: 6,673,859\n",
      "_________________________________________________________________\n",
      "---------------------------------------------------------------\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, None, None, 3)]   0         \n",
      "                                                                 \n",
      " unet_model (Functional)     (None, None, None, 1)     31172417  \n",
      "                                                                 \n",
      " model (Functional)          (None, 1)                 6673859   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 37,846,276\n",
      "Trainable params: 16,450,049\n",
      "Non-trainable params: 21,396,227\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_height = None\n",
    "input_width = None\n",
    "c_dim = 3\n",
    "lr = 1e-3\n",
    "G = GAN(input_height, input_width, c_dim)\n",
    "image_dims = (input_height, input_width, c_dim)\n",
    "generator = G.build_segmentor()\n",
    "generator.compile(optimizer='adam', loss= FocalTverskyLoss, metrics = [\"accuracy\",dice_coef, jaccard_score,\n",
    "                                        tf.keras.metrics.Precision(),tf.keras.metrics.Recall(),Tversky,\n",
    "                                        tf.keras.metrics.FalsePositives(),tf.keras.metrics.FalseNegatives()])\n",
    "\n",
    "img = Input(shape=image_dims)\n",
    "reconstructed_img = generator(img)\n",
    "\n",
    "discriminator = G.build_discriminator()\n",
    "discriminator.compile(optimizer= 'adam', loss='binary_crossentropy')\n",
    "discriminator.trainable = False\n",
    "discriminator.compile(optimizer= 'adam', loss = 'binary_crossentropy')\n",
    "validity = discriminator(reconstructed_img)\n",
    "\n",
    "\n",
    "adversarial_model = Model(img, [reconstructed_img, validity])\n",
    "adversarial_model.compile(loss=[FocalTverskyLoss, 'binary_crossentropy'],\n",
    "    optimizer= 'adam', metrics = [\"accuracy\"])\n",
    "generator.summary()\n",
    "print(\"---------------------------------------------------------------\")\n",
    "discriminator.summary()\n",
    "print(\"---------------------------------------------------------------\")\n",
    "adversarial_model.summary()\n",
    "\n",
    "K.set_value(generator.optimizer.lr, lr)\n",
    "K.set_value(discriminator.optimizer.lr, lr)\n",
    "K.set_value(adversarial_model.optimizer.lr, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s7O4lP05xcwl",
    "outputId": "98b61f3f-8316-426d-81f4-0344e9711a4b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6277"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "hcqpvjc_xcwl"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def visualize(image_batch, mask_batch=None, pred_batch=None, num_samples = None):\n",
    "    num_classes = mask_batch.shape[-1] if mask_batch is not None else 0\n",
    "    fix, ax = plt.subplots(num_classes + 1, num_samples, figsize=(num_samples * 2, (num_classes + 1) * 2))\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        ax_image = ax[0, i] if num_classes > 0 else ax[i]\n",
    "        ax_image.imshow(image_batch[i,:,:,0], cmap='gray')\n",
    "        ax_image.set_xticks([]) \n",
    "        ax_image.set_yticks([])\n",
    "        \n",
    "        if mask_batch is not None:\n",
    "            for j in range(num_classes):\n",
    "                if pred_batch is None:\n",
    "                    mask_to_show = mask_batch[i,:,:,j]\n",
    "                else:\n",
    "                    mask_to_show = np.zeros(shape=(*mask_batch.shape[1:-1], 3)) \n",
    "                    mask_to_show[..., 0] = pred_batch[i,:,:,j] > 0.5\n",
    "                    mask_to_show[..., 1] = mask_batch[i,:,:,j]\n",
    "                ax[j + 1, i].imshow(mask_to_show, vmin=0, vmax=1)\n",
    "                ax[j + 1, i].set_xticks([]) \n",
    "                ax[j + 1, i].set_yticks([]) \n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "mQpBEEkUxcwl"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.clear_session()\n",
    "tf.compat.v1.reset_default_graph()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G8JX4PjRxcwm",
    "outputId": "d2353258-2986-4446-d9be-709814d8a3f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 13s 308ms/step - loss: 0.9565 - accuracy: 0.0584 - dice_coef: 0.0845 - jaccard_score: 0.0297 - precision: 0.0331 - recall: 0.9176 - Tversky: 0.0898 - false_positives: 46746404.0000 - false_negatives: 143808.0000\n"
     ]
    }
   ],
   "source": [
    "val = generator.evaluate(Valid_Images, Valid_Masks, batch_size = 32, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "import time\n",
    "h = 256\n",
    "w = 256\n",
    "c = 3\n",
    "J=0\n",
    "lr = 1e-3\n",
    "min_loss = val[0]\n",
    "K.set_value(generator.optimizer.lr, lr)\n",
    "K.set_value(discriminator.optimizer.lr, lr)\n",
    "K.set_value(adversarial_model.optimizer.lr, lr)\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "steps_per_epoch = 2026//batch_size\n",
    "#validation_steps = 4\n",
    "for epoch in range(epochs):\n",
    "        print('Epoch ({}/{})-------------------------------------------------'.format(epoch,epochs))\n",
    "\n",
    "        for i in tqdm(range(steps_per_epoch)):\n",
    "        #              batch_x = np.array([next(train_image_generator) for i in range(batch_size)]).reshape(batch_size,target_x, target_y,3)\n",
    "        #     batch_y = np.array([next(train_mask_generator) for i in range(batch_size)]).reshape(batch_size,target_x, target_y,1)\n",
    "        #     \"\"\"\n",
    "            x_train,y_train = next(train_generator)\n",
    "#             x_train = get_patches(x_train,h,w,ph,pw,c).reshape(-1,ph,pw,c)\n",
    "#             y_train = get_patches(y_train,h,w,ph,pw,c).reshape(-1,ph,pw,c)\n",
    "            \n",
    "#             x_train,y_train = remove_black_images(x_train,y_train, 0)\n",
    "            gc.collect()    \n",
    "         \n",
    "            \n",
    "            ones = np.ones((y_train.shape[0], 1)) - np.random.uniform(0.001, 0.1)\n",
    "            zeros = np.zeros((y_train.shape[0], 1)) + np.random.uniform(0.001, 0.1)\n",
    "            discriminator.trainable = True\n",
    "            batch_fake_images = generator.predict_on_batch(x_train)\n",
    "\n",
    "            discriminator.train_on_batch(y_train, ones)\n",
    "            discriminator.train_on_batch(batch_fake_images, zeros)\n",
    "\n",
    "            gc.collect()      \n",
    "            del batch_fake_images\n",
    "            discriminator.trainable = False\n",
    "            \n",
    "            adversarial_model.train_on_batch(x_train, [y_train,ones])  \n",
    "        val = generator.evaluate(Valid_Images, Valid_Masks, batch_size = 32, verbose = 1)\n",
    "\n",
    "        l = val[0]\n",
    "        if (l <= min_loss):\n",
    "            print(\"val_loss progressed to: \", val)\n",
    "            min_loss = l\n",
    "            generator.save_weights(\"Segmentation GAN WEIGHTS/2D/UNET/gen_UNET_GAN.h5\")\n",
    "            discriminator.save_weights(\"Segmentation GAN WEIGHTS/2D/UNET/dis_UNET_GAN.h5\")\n",
    "            J=0\n",
    "        \n",
    "#                 generator.load_weights(\"{}/gen_UNET_NRC2D_COVID_{}_{} P_ {} R.h5\".format(directory,Version, best_precision, best_recall))\n",
    "#                 discriminator.load_weights(\"{}/dis_UNET_NRC2D_COVID_{}_{} P_ {} R.h5\".format(directory, Version, best_precision, best_recall))\n",
    "        else: \n",
    "            J+=1\n",
    "            if J == 10:\n",
    "                lr = lr*0.5\n",
    "                K.set_value(generator.optimizer.lr, lr)\n",
    "                K.set_value(discriminator.optimizer.lr, lr)\n",
    "                K.set_value(adversarial_model.optimizer.lr, lr)\n",
    "                J=0\n",
    "                print(\"lr reduced to: \", lr)\n",
    "#                 generator.load_weights(\"{}/gen_UNET_NRC2D_COVID_{}_{} P_ {} R.h5\".format(directory,Version, best_precision, best_recall))\n",
    "#                 discriminator.load_weights(\"{}/dis_UNET_NRC2D_COVID_{}_{} P_ {} R.h5\".format(directory, Version, best_precision, best_recall))\n",
    "        x, y = Valid_Images[100:108], Valid_Masks[100:108]\n",
    "        preds = adversarial_model.predict_on_batch(x)[0]\n",
    "        visualize(x,y, pred_batch = preds, num_samples=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os._exit(00)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "2D GAN_COVID_UNET_NRC.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
